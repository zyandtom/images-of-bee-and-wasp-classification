{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Adversarial_Demo.ipynb","provenance":[],"private_outputs":true,"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"J6pIQ_CtOGJq"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vag2WYR6yTOC"},"source":["from __future__ import absolute_import, division, print_function, unicode_literals\n","\n","try:\n","  # %tensorflow_version only exists in Colab.\n","  %tensorflow_version 2.x\n","except Exception:\n","  pass\n","import tensorflow as tf\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","from pylab import *\n","\n","mpl.rcParams['figure.figsize'] = (8, 8)\n","mpl.rcParams['axes.grid'] = False"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XGCdmDAKpLuf"},"source":["##### Copyright 2019 The TensorFlow Authors.\n","\n","Licensed under the Apache License, Version 2.0 (the \"License\");"]},{"cell_type":"markdown","metadata":{"id":"wiTHY8dqxzx7"},"source":["Let's pick and load a pretrained model! \n","Or build your own, save as .h5 file, load!"]},{"cell_type":"code","metadata":{"id":"nqhk2vYx6Ag0"},"source":["pretrained_model = tf.keras.applications.MobileNetV2(include_top=True,weights='imagenet')\n","\n","#pretrained_model = tf.keras.applications.resnet50.ResNet50(include_top=True,weights='imagenet')\n","\n","pretrained_modelv3 = tf.keras.applications.inception_v3.InceptionV3(include_top=True,weights='imagenet')\n","\n","pretrained_modelna = tf.keras.applications.nasnet.NASNetMobile(include_top=True, weights='imagenet')\n","\n","pretrained_model.trainable = False\n","\n","# ImageNet labels #Decoder is the same for all pretrained imagenet models.\n","decode_predictions = tf.keras.applications.mobilenet_v2.decode_predictions "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f2cLrJH0zpfC"},"source":["# Helper function to preprocess the image so that it can be inputted in MobileNetV2\n","def preprocess(image):\n","  image = tf.cast(image, tf.float32)\n","  image = image/255\n","  image = image / tf.math.reduce_max(image)\n","  image = tf.image.resize(image, (224, 224))\n","  image = image[None, ...]\n","  return image\n","\n","# Helper function to extract labels from probability vector\n","def get_imagenet_label(probs):\n","  return decode_predictions(probs, top=1)[0][0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wpYrQ4OQSYWk"},"source":["#Upload any imag\n","image_raw = tf.io.read_file(\"/content/drive/My Drive/MLha4/images/2.png\")\n","\n","\n","image = tf.image.decode_image(image_raw,3)\n","\n","image = preprocess(image)\n","image_probs = pretrained_model.predict(image)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fIE7o5ovRbz4"},"source":["# #Upload any image\n","# image_raw = []\n","# image_raw.append(tf.io.read_file(\"/content/drive/My Drive/MLha4/images/1.png\"))\n","# image_raw.append(tf.io.read_file(\"/content/drive/My Drive/MLha4/images/2.png\"))\n","# image_raw.append(tf.io.read_file(\"/content/drive/My Drive/MLha4/images/3.png\"))\n","# image_raw.append(tf.io.read_file(\"/content/drive/My Drive/MLha4/images/4.png\"))\n","# image_raw.append(tf.io.read_file(\"/content/drive/My Drive/MLha4/images/5.png\"))\n","# image_raw.append(tf.io.read_file(\"/content/drive/My Drive/MLha4/images/6.png\"))\n","# image_raw.append(tf.io.read_file(\"/content/drive/My Drive/MLha4/images/7.png\"))\n","# image_raw.append(tf.io.read_file(\"/content/drive/My Drive/MLha4/images/8.png\"))\n","# image_raw.append(tf.io.read_file(\"/content/drive/My Drive/MLha4/images/9.png\"))\n","# image_raw.append(tf.io.read_file(\"/content/drive/My Drive/MLha4/images/10.png\"))\n","# subplots_adjust(left=0,bottom=0.1,top=1.1,right=1.2)\n","# for i in range(len(image_raw)):\n","\n","#   image = tf.image.decode_image(image_raw[i],3)\n","\n","#   image = preprocess(image)\n","#   image_probs = pretrained_model.predict(image)\n","\n","#   plt.subplot(3, 4, i+1)\n","#   plt.imshow(image[0])\n","#   _, image_class, class_confidence = get_imagenet_label(image_probs)\n","#   plt.title('{} : {:.2f}% Confidence'.format(image_class, class_confidence*100), fontsize=10)\n","# plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zdzqs2kZh0ih"},"source":["image.shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mvPlta_uSbuI"},"source":["Let's have a look at the image."]},{"cell_type":"code","metadata":{"id":"99Jc-SNoSZot"},"source":["plt.figure()\n","plt.imshow(image[0])\n","_, image_class, class_confidence = get_imagenet_label(image_probs)\n","plt.title('{} : {:.2f}% Confidence'.format(image_class, class_confidence*100))\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kElVTbF690CF"},"source":["## Create the adversarial image\n","\n","### Implementing fast gradient sign method\n","The first step is to create perturbations which will be used to distort the original image resulting in an adversarial image. As mentioned, for this task, the gradients are taken with respect to the image."]},{"cell_type":"code","metadata":{"id":"FhZxlOnuBCVr"},"source":["loss_object = tf.keras.losses.CategoricalCrossentropy()\n","\n","def create_adversarial_pattern(input_image, input_label):\n","  with tf.GradientTape() as tape:\n","    tape.watch(input_image) \n","    prediction = pretrained_model(input_image)\n","    loss = loss_object(input_label, prediction)\n","\n","  # Get the gradients of the loss w.r.t to the input image.\n","  gradient = tape.gradient(loss, input_image)\n","  # Get the sign of the gradients to create the perturbation\n","  signed_grad = tf.sign(gradient)\n","  return signed_grad, gradient "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RbuftX0eSlDQ"},"source":["The resulting perturbations can also be visualised."]},{"cell_type":"code","metadata":{"id":"rVjnb6M7Smv4"},"source":["# Get the input label of the image.\n","labrador_retriever_index = 84\n","label = tf.one_hot(labrador_retriever_index, image_probs.shape[-1])\n","label = tf.reshape(label, (1, image_probs.shape[-1]))\n","\n","perturbations , enhance = create_adversarial_pattern(image, label)\n","plt.imshow(perturbations[0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"W5h43KY9i2ZQ"},"source":["perturbations.shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DKKSFHjwCyQH"},"source":["Let's try this out for different values of epsilon and observe the resultant image. You'll notice that as the value of epsilon is increased, it becomes easier to fool the network. However, this comes as a trade-off which results in the perturbations becoming more identifiable."]},{"cell_type":"code","metadata":{"id":"dBtG0Kl5SspV"},"source":["def display_images(image, description):\n","  \n","  _, label, confidence = get_imagenet_label(pretrained_model.predict(image))\n","  plt.figure()\n","  plt.imshow(image[0])\n","  plt.title('{} \\n {} : {:.2f}% Confidence'.format(description, label, confidence*100))\n","  plt.show()\n","  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Wb6EF-1lUow"},"source":["epsilons = [0, 0.001, 0.01, 0.1, 0.5]\n","descriptions = [('Epsilon = {:0.3f}'.format(eps) if eps else 'Input')\n","                for eps in epsilons]\n","labelist = []\n","confidencelist = []\n","\n","for i, eps in enumerate(epsilons):\n","  adv_x = eps*perturbations + image \n","  adv_x = tf.clip_by_value(adv_x, 0, 1)\n","  #display_images(adv_x, descriptions[i])\n","  \n","  #自加\n","  _, label, confidence = get_imagenet_label(pretrained_model.predict(adv_x))\n","  labelist.append(label)\n","  confidencelist.append(confidence)\n","print(labelist)\n","print(confidencelist)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nIDh5MFgjtck"},"source":["# #展示加了perturbation的图片10行5列\n","# image_raw = []\n","# image_raw.append(tf.io.read_file(\"/content/drive/My Drive/MLha4/images/1.png\"))\n","# image_raw.append(tf.io.read_file(\"/content/drive/My Drive/MLha4/images/2.png\"))\n","# image_raw.append(tf.io.read_file(\"/content/drive/My Drive/MLha4/images/3.png\"))\n","# image_raw.append(tf.io.read_file(\"/content/drive/My Drive/MLha4/images/4.png\"))\n","# image_raw.append(tf.io.read_file(\"/content/drive/My Drive/MLha4/images/5.png\"))\n","# image_raw.append(tf.io.read_file(\"/content/drive/My Drive/MLha4/images/6.png\"))\n","# image_raw.append(tf.io.read_file(\"/content/drive/My Drive/MLha4/images/7.png\"))\n","# image_raw.append(tf.io.read_file(\"/content/drive/My Drive/MLha4/images/8.png\"))\n","# image_raw.append(tf.io.read_file(\"/content/drive/My Drive/MLha4/images/9.png\"))\n","# image_raw.append(tf.io.read_file(\"/content/drive/My Drive/MLha4/images/10.png\"))\n","# #subplots_adjust(left=0,bottom=0.1,top=1.4,right=1.2)\n","# labrador_retriever_index = [984, 84, 915, 604, 900, 340, 779, 721, 554, 476]\n","# plt.figure(figsize=(18,42))\n","# for i in range(len(image_raw)):\n","#   #预处理图片\n","#   image = tf.image.decode_image(image_raw[i],3)\n","#   image = preprocess(image)\n","#   image_probs = pretrained_model.predict(image)\n","\n","#   #加扰动\n","#   label = tf.one_hot(labrador_retriever_index[i], image_probs.shape[-1])\n","#   label = tf.reshape(label, (1, image_probs.shape[-1]))\n","#   perturbations , enhance = create_adversarial_pattern(image, label)\n","\n","#   #显示\n","#   epsilons = [0, 0.001, 0.01, 0.1, 0.5]\n","#   descriptions = [('Epsilon = {:0.3f}'.format(eps) if eps else 'Input')\n","#                   for eps in epsilons]\n","#   labelist = []\n","#   confidencelist = []\n","\n","#   for j, eps in enumerate(epsilons):\n","#     adv_x = eps*perturbations + image \n","#     adv_x = tf.clip_by_value(adv_x, 0, 1)\n","#     _, label, confidence = get_imagenet_label(pretrained_model.predict(adv_x))\n","#     plt.subplot(10, 5, i*5+j+1)\n","#     plt.imshow(adv_x[0])\n","#     plt.title('{} \\n {} : {:.2f}% Confidence'.format(descriptions[j], label, confidence*100), fontsize=11)\n","# plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wyad6d6PSLtY"},"source":["#transfer\n","pretrained_modelv3 = tf.keras.applications.inception_v3.InceptionV3(include_top=True,weights='imagenet')\n","\n","epsilons = [0, 0.001, 0.01, 0.1, 0.5]\n","descriptions = [('Epsilon = {:0.3f}'.format(eps) if eps else 'Input')\n","                for eps in epsilons]\n","labelist = []\n","confidencelist = []\n","\n","for i, eps in enumerate(epsilons):\n","  adv_x = eps*perturbations + image \n","  adv_x = tf.clip_by_value(adv_x, 0, 1)\n","  #display_images(adv_x, descriptions[i])\n","  \n","  #自加\n","  _, label, confidence = get_imagenet_label(pretrained_modelv3.predict(adv_x))\n","  labelist.append(label)\n","  confidencelist.append(confidence)\n","print(labelist)\n","print(confidencelist)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gm11rklSyx5Q"},"source":["We can look at different intensity of perturbation and what model sees\n"]},{"cell_type":"code","metadata":{"id":"3DA8g-Zp69J4"},"source":["epsilons = [0, 0.2, 1]\n","descriptions = [('Epsilon = {:0.3f}'.format(eps) if eps else 'Input')\n","                for eps in epsilons]\n","\n","for i, eps in enumerate(epsilons):\n","  adv_x = eps*perturbations# + image \n","  adv_x = tf.clip_by_value(adv_x, 0, 1)\n","  display_images(adv_x, descriptions[i])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FKrLp-QYy9Bh"},"source":["We can also add different noise level to \"enhance\" the confidence of model.\n","However, adding too much will hurt more than help"]},{"cell_type":"markdown","metadata":{"id":"TLbuGDROzL40"},"source":["Note that now the noise added is **negative of gradient**.\n","This is what we usually do for gradient descend\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"vPKOxkkG49--"},"source":["Iterative attack:\n","First, pick a class index.\n","Then start the attack!"]},{"cell_type":"code","metadata":{"id":"1ISi8B3ue3gq"},"source":["fig1 = plt.figure(figsize=(15,20))\n","import pandas as pd\n","import seaborn as sns\n","for m in range(1, 11):\n","  image_raw = tf.io.read_file(\"/content/drive/My Drive/MLha4/images/{}.png\".format(m))\n","  image = tf.image.decode_image(image_raw,3)\n","\n","  image = preprocess(image)\n","\n","  index = 1 #Find class index here: https://github.com/USCDataScience/dl4j-kerasimport-examples/blob/master/dl4j-import-example/data/imagenet_class_index.json\n","\n","  image_probs = pretrained_model.predict(image)\n","  label = tf.one_hot(index, image_probs.shape[-1])\n","  label = tf.reshape(label, (1, image_probs.shape[-1]))\n","  perturbations , enhance = create_adversarial_pattern(image, label)\n","  accumulated = 0*image #accumulate gradients over the iterations\n","\n","  labelist1 = []\n","  confidencelist1 = []\n","  for j in range(100): #Most attacks will start to show result before 100 iterations\n","\n","    epsilons = [-0.03]\n","    descriptions = [('Epsilon = {:0.3f}'.format(eps) if eps else 'Input')\n","                    for eps in epsilons]\n","    \n","    for i, eps in enumerate(epsilons):\n","      accumulated = eps*enhance + accumulated\n","      adv_x = eps*enhance + image \n","      adv_x = tf.clip_by_value(adv_x, 0, 1)\n","      #display_images(adv_x, j)\n","\n","      _, label1, confidence = get_imagenet_label(pretrained_model.predict(adv_x))\n","      labelist1.append(label1)\n","      confidencelist1.append(confidence)\n","    perturbations , enhance = create_adversarial_pattern(image, label)\n","    image = adv_x\n","  xaxis = []\n","  for n in range(1, 101): xaxis.append(n)\n","  # print(labelist1)\n","  # print(confidencelist1)\n","  data = {'iterations':xaxis,\n","       'confidence':confidencelist1,\n","       'label':labelist1\n","       }\n","  df = pd.DataFrame(data)\n","  axk = fig1.add_subplot(4, 3, m)\n","  chart = sns.lineplot(y='confidence', x='iterations', hue='label', data=df, ax=axk)\n","  axk.set_title('image{}'.format(m))\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-m2cjp8KcaR_"},"source":["display_images(accumulated, j)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uSWuNJ5xsphR"},"source":["display_images(accumulated*50, j)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cLHO3iEigonc"},"source":["image_raw = tf.io.read_file(\"/content/drive/My Drive/MLha4/images/2.png\")\n","image = tf.image.decode_image(image_raw,3)\n","\n","image = preprocess(image)\n","display_images(accumulated*1+image, j)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ia_U08zNkGAY"},"source":["This approach is not an Universial attack."]},{"cell_type":"markdown","metadata":{"id":"yVp3yegpOgwk"},"source":["Some fast exercises:\n","\n","1. Try create Universial attack  \n","2. Test transferability of attack on different models. \n","3. Plot and analyze accuracy lost among different models per iteration\n","\n","\n"]}]}